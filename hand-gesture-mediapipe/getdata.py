import cv2
import mediapipe as mp
import numpy as np
import os
import csv
import time

# Kh·ªüi t·∫°o MediaPipe Hands
mp_hands = mp.solutions.hands
mp_drawing = mp.solutions.drawing_utils
hands = mp_hands.Hands(max_num_hands=1, min_detection_confidence=0.7, min_tracking_confidence=0.7)

# C·∫•u h√¨nh th√¥ng s·ªë video
fps = 30  # S·ªë khung h√¨nh m·ªói gi√¢y
duration = 3  # Th·ªùi gian thu (gi√¢y)
total_frames = fps * duration  # T·ªïng s·ªë frame c·∫ßn ghi (90)

# M·ªü webcam
cap = cv2.VideoCapture(0)
frame_width, frame_height = int(cap.get(3)), int(cap.get(4))

if not cap.isOpened():
    print("‚ùå Kh√¥ng th·ªÉ m·ªü webcam!")
    exit()

# Nh·∫≠p t√™n c·ª≠ ch·ªâ
gesture_name = "Stop"
dataset_path = f"D:/HAND-GESTURE/hand-gesture-mediapipe/DataSet/Stop"
video_path = os.path.join(dataset_path, "Videos")
csv_path = os.path.join(dataset_path, f"Stop80.csv")

# T·∫°o th∆∞ m·ª•c n·∫øu ch∆∞a c√≥
os.makedirs(video_path, exist_ok=True)

# ƒê·∫øm s·ªë video ƒë√£ c√≥ ƒë·ªÉ ƒë·∫∑t t√™n file
video_index = len(os.listdir(video_path))
video_filename = os.path.join(video_path, f"{gesture_name}_{video_index}.mp4")

# Ghi video
fourcc = cv2.VideoWriter_fourcc(*'mp4v')
out = cv2.VideoWriter(video_filename, fourcc, fps, (frame_width, frame_height))

print(f"\nüé• B·∫Øt ƒë·∫ßu thu video {video_index + 1} ({gesture_name}) trong 3 gi√¢y...")

keypoints_list = []
start_time = time.time()

while time.time() - start_time < duration:  # T·ª± d·ª´ng sau 3 gi√¢y
    ret, frame = cap.read()
    if not ret:
        print("‚ùå Kh√¥ng th·ªÉ ƒë·ªçc t·ª´ camera.")
        break

    frame = cv2.flip(frame, 1)  # L·∫≠t ·∫£nh ƒë·ªÉ ƒë√∫ng chi·ªÅu

    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    result = hands.process(rgb_frame)

    keypoints = []
    if result.multi_hand_landmarks:
        for hand_landmarks in result.multi_hand_landmarks:
            mp_drawing.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)

            # Tr√≠ch xu·∫•t t·ªça ƒë·ªô keypoints (21 ƒëi·ªÉm * 3 t·ªça ƒë·ªô = 63)
            keypoints = [coord for lm in hand_landmarks.landmark for coord in (lm.x, lm.y, lm.z)]

    # L∆∞u keypoints v√†o danh s√°ch n·∫øu ƒë·ªß 63 ƒëi·ªÉm
    if len(keypoints) == 63:
        keypoints_list.append(keypoints)

    # V·∫Ω th·ªùi gian c√≤n l·∫°i l√™n m√†n h√¨nh
    elapsed_time = time.time() - start_time
    remaining_time = max(0, duration - elapsed_time)
    cv2.putText(frame, f"Time: {remaining_time:.1f}s", (30, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)

    # Ghi video
    out.write(frame)
    cv2.imshow("Recording", frame)

    if cv2.waitKey(1) & 0xFF == ord('q'):
        print("‚èπ D·ª´ng s·ªõm do nh·∫•n 'q'")
        break

out.release()

# Ghi t·ªça ƒë·ªô v√†o CSV
with open(csv_path, mode="a", newline="") as file:
    writer = csv.writer(file)
    for keypoints in keypoints_list:
        writer.writerow(keypoints + [gesture_name])

print(f"Video ƒë√£ l∆∞u t·∫°i {video_filename}")
cap.release()
cv2.destroyAllWindows()
print("Ho√†n th√†nh thu th·∫≠p d·ªØ li·ªáu!")
